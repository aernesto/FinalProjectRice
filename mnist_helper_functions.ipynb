{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#helper_functions\n",
    "#________________________________________________\n",
    "def weight_variable(shape):\n",
    "    '''\n",
    "    Initialize weights\n",
    "    :param shape: shape of weights, e.g. [w, h ,Cin, Cout] where\n",
    "    w: width of the filters\n",
    "    h: height of the filters\n",
    "    Cin: the number of the channels of the filters\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor variable for weights with initial values\n",
    "    '''\n",
    "    initial_W = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial_W)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    '''\n",
    "    Initialize biases\n",
    "    :param shape: shape of biases, e.g. [Cout] where\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor variable for biases with initial values\n",
    "    '''\n",
    "    initial_b = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial_b)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    '''\n",
    "    Perform 2-D convolution\n",
    "    :param x: input tensor of size [N, W, H, Cin] where\n",
    "    N: the number of images\n",
    "    W: width of images\n",
    "    H: height of images\n",
    "    Cin: the number of channels of images\n",
    "    :param W: weight tensor [w, h, Cin, Cout]\n",
    "    w: width of the filters\n",
    "    h: height of the filters\n",
    "    Cin: the number of the channels of the filters = the number of channels of images\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor of features extracted by the filters, a.k.a. the results after convolution\n",
    "    '''\n",
    "    h_conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return h_conv\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    '''\n",
    "    Perform non-overlapping 2-D maxpooling on 2x2 regions in the input data\n",
    "    :param x: input data\n",
    "    :return: the results of maxpooling (max-marginalized + downsampling)\n",
    "    '''\n",
    "    h_max = tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return h_max\n",
    "\n",
    "#counting the total number of parameters in our network\n",
    "def param_counter():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        #print(shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        #print(variable_parameters)\n",
    "        total_parameters += variable_parameters\n",
    "    print(\"total number of parameters:\", total_parameters)\n",
    "\n",
    "\n",
    "def mnist_inference(x_image, y_, keep_prob, nh1, nh2, nh3, num_classes):\n",
    "    # first convolutional layer\n",
    "    #nh1 = 32\n",
    "    input_channels = 1\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = tf.get_variable('W_conv1', shape = [5, 5, input_channels, nh1], \n",
    "                                    initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                    dtype=tf.float32)\n",
    "        b_conv1 = bias_variable([nh1])\n",
    "\n",
    "        h_conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "        h_bnorm1= tf.contrib.layers.batch_norm(h_conv1, epsilon=1e-5, scope='bn1')\n",
    "        h_act1  = tf.nn.relu(h_bnorm1)\n",
    "        with tf.name_scope('conv1_output'):\n",
    "            h_pool1 = max_pool_2x2(h_act1)\n",
    "\n",
    "    # second convolutional layer\n",
    "    #nh2 = 64\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = tf.get_variable('W_conv2', shape = [5, 5, nh1, nh2], \n",
    "                                    initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                    dtype=tf.float32)\n",
    "        b_conv2 = bias_variable([nh2])\n",
    "        h_conv2 = conv2d(h_pool1, W_conv2) + b_conv2\n",
    "        h_bnorm2= tf.contrib.layers.batch_norm(h_conv2, epsilon=1e-5, scope='bn2')\n",
    "        h_act2  = tf.nn.relu(h_bnorm2)\n",
    "        with tf.name_scope('conv2_output'):\n",
    "            h_pool2 = max_pool_2x2(h_act2)\n",
    "\n",
    "    # densely connected layer\n",
    "    #nh3 = 1024\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = tf.get_variable('W_fc1', shape = [7 * 7 * nh2, nh3], \n",
    "                                 initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                 dtype=tf.float32)\n",
    "        b_fc1 = bias_variable([nh3])\n",
    "\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * nh2])\n",
    "        with tf.name_scope('fc1_output'):\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # dropout\n",
    "    with tf.name_scope('dropout'):\n",
    "        with tf.name_scope('dropout_output'):\n",
    "            h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # softmax\n",
    "    #num_classes = 10\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = tf.get_variable('W_fc2', shape =[nh3, num_classes], \n",
    "                                 initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                                 dtype=tf.float32)\n",
    "        b_fc2 = bias_variable([num_classes])\n",
    "        with tf.name_scope('net_output'):\n",
    "            y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    #loss function\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "                        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    \n",
    "    #correct_predictions and accuracy\n",
    "    with tf.name_scope('predictions'):\n",
    "        correct_prediction  = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "        correct_prediction  = tf.cast(correct_prediction, tf.float32)\n",
    "        with tf.name_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(correct_prediction)\n",
    "    return (y_conv, cross_entropy, correct_prediction, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
